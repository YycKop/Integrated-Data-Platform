# Copyright (c) 2025 YycKop
# MIT License
# Integrated-Data-Platform-backend/visualization/views.py
from rest_framework import viewsets, permissions, status
from rest_framework.decorators import action
from rest_framework.response import Response
from django.db.models import Count
from .models import ChartType, Visualization, Dashboard, DashboardItem
from .serializers import (
    ChartTypeSerializer,
    VisualizationSerializer,
    DashboardSerializer,
    DashboardItemSerializer
)
from datasets.models import DataRecord
import pandas as pd
import json
import math


class ChartTypeViewSet(viewsets.ReadOnlyModelViewSet):
    """
    å›¾è¡¨ç±»å‹è§†å›¾é›† - åªè¯»ï¼Œç”¨äºå‰ç«¯é€‰æ‹©å›¾è¡¨ç±»å‹
    """
    queryset = ChartType.objects.all()
    serializer_class = ChartTypeSerializer
    permission_classes = [permissions.IsAuthenticated]


class VisualizationViewSet(viewsets.ModelViewSet):
    serializer_class = VisualizationSerializer
    permission_classes = [permissions.IsAuthenticated]

    def get_queryset(self):
        return Visualization.objects.filter(created_by=self.request.user)

    def perform_create(self, serializer):
        serializer.save(created_by=self.request.user)

    @action(detail=True, methods=['get'])
    def data(self, request, pk=None):
        """
        è·å–å¯è§†åŒ–å›¾è¡¨æ•°æ® - ä¿®å¤ç‰ˆ
        """
        try:
            visualization = self.get_object()
            dataset = visualization.dataset

            # è·å–æ•°æ®é›†çš„æ‰€æœ‰è®°å½•
            records = DataRecord.objects.filter(dataset=dataset)
            if not records.exists():
                print("âŒ æ•°æ®é›†ä¸ºç©º")
                return Response({
                    'visualization_id': visualization.id,
                    'chart_type': visualization.chart_type.name,
                    'data': {'categories': [], 'series': []},
                    'config': visualization.configuration,
                    'message': 'æ•°æ®é›†ä¸ºç©º'
                })

            data = [record.data for record in records]

            # è½¬æ¢ä¸ºDataFrameè¿›è¡Œå¤„ç†
            df = pd.DataFrame(data)
            print(f"âœ… åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
            print(f"âœ… æ•°æ®åˆ—: {df.columns.tolist()}")
            print(f"âœ… æ•°æ®å‰5è¡Œ:\n{df.head()}")

            # æ ¹æ®å¯è§†åŒ–é…ç½®å¤„ç†æ•°æ®
            config = visualization.configuration
            chart_data = self._prepare_chart_data(df, config, visualization.chart_type)

            print(f"âœ… ç”Ÿæˆçš„å›¾è¡¨æ•°æ®: {chart_data}")

            return Response({
                'visualization_id': visualization.id,
                'chart_type': visualization.chart_type.name,
                'data': chart_data,
                'config': config,
                'message': 'æ•°æ®åŠ è½½æˆåŠŸ'
            })

        except Exception as e:
            print(f"âŒ è·å–å›¾è¡¨æ•°æ®é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return Response(
                {'error': f'è·å–å›¾è¡¨æ•°æ®å¤±è´¥: {str(e)}'},
                status=status.HTTP_400_BAD_REQUEST
            )

    @action(detail=False, methods=['get'])
    def dataset_columns(self, request):
        """æ ¹æ®æ•°æ®é›†IDè·å–åˆ—å"""
        try:
            dataset_id = request.query_params.get('dataset_id')
            if not dataset_id:
                return Response({'columns': []})

            from datasets.models import Dataset
            dataset = Dataset.objects.filter(id=dataset_id).first()

            if not dataset:
                return Response({'columns': []})

            # å¤ç”¨æ•°æ®å¤„ç†æ¨¡å—çš„å­—æ®µè·å–é€»è¾‘
            records = dataset.datarecord_set.all()[:10]
            if records:
                all_columns = set()
                for record in records:
                    if record.data:
                        all_columns.update(record.data.keys())
                columns = list(all_columns)
                return Response({'columns': columns})
            else:
                return Response({'columns': []})

        except Exception as e:
            logger.error(f"Get dataset columns error: {str(e)}")
            return Response({'columns': []})

    def _prepare_chart_data(self, df, config, chart_type):
        """å‡†å¤‡å›¾è¡¨æ•°æ® - ä¿®å¤ç‰ˆ"""
        print(f"ğŸ” å¼€å§‹å‡†å¤‡å›¾è¡¨æ•°æ®")
        print(f"ğŸ” å›¾è¡¨ç±»å‹: {chart_type.name}")
        print(f"ğŸ” é…ç½®: {config}")

        if df.empty:
            print("âŒ æ•°æ®ä¸ºç©º")
            return self._get_empty_chart_data(chart_type.name)

        try:
            # æ¸…ç†æ•°æ®ï¼Œå¤„ç†NaNå€¼
            df = df.fillna(0)
            print(f"âœ… æ¸…ç†åæ•°æ®å½¢çŠ¶: {df.shape}")

            if chart_type.name == 'æŸ±çŠ¶å›¾':
                return self._prepare_bar_chart_data(df, config)
            elif chart_type.name == 'æŠ˜çº¿å›¾':
                return self._prepare_line_chart_data(df, config)
            elif chart_type.name == 'é¥¼å›¾':
                return self._prepare_pie_chart_data(df, config)
            elif chart_type.name == 'æ•£ç‚¹å›¾':
                return self._prepare_scatter_chart_data(df, config)
            elif chart_type.name == 'é›·è¾¾å›¾':
                return self._prepare_radar_chart_data(df, config)
            elif chart_type.name == 'åœ°å›¾':
                return self._prepare_map_chart_data(df, config)  # æ–°å¢åœ°å›¾å¤„ç†
            else:
                print(f"âš ï¸ æœªçŸ¥å›¾è¡¨ç±»å‹: {chart_type.name}")
                return self._get_default_chart_data(df)
        except Exception as e:
            print(f"âŒ å›¾è¡¨æ•°æ®å¤„ç†é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return self._get_empty_chart_data(chart_type.name)

    def _get_empty_chart_data(self, chart_type):
        """è¿”å›ç©ºçš„å›¾è¡¨æ•°æ®ç»“æ„"""
        empty_data = {
            'æŸ±çŠ¶å›¾': {'categories': [], 'series': []},
            'æŠ˜çº¿å›¾': {'categories': [], 'series': []},
            'é¥¼å›¾': {'data': []},
            'æ•£ç‚¹å›¾': {'data': []},
            'é›·è¾¾å›¾': {'indicators': [], 'series': []},
            'åœ°å›¾': {'data': []}  # æ–°å¢åœ°å›¾ç©ºæ•°æ®
        }
        return empty_data.get(chart_type, {'data': []})

    def _get_default_chart_data(self, df):
        """è¿”å›é»˜è®¤å›¾è¡¨æ•°æ®"""
        return {
            'categories': list(df.columns) if not df.empty else [],
            'series': [{
                'name': 'æ•°æ®',
                'data': df.iloc[:, 0].tolist() if not df.empty else []
            }]
        }

    # ä¿®å¤æŸ±çŠ¶å›¾æ•°æ®å¤„ç†
    def _prepare_bar_chart_data(self, df, config):
        """å‡†å¤‡æŸ±çŠ¶å›¾æ•°æ® - ä¿®å¤ç‰ˆ"""
        x_field = config.get('xField', '')
        y_field = config.get('yField', '')

        print(f"ğŸ” æŸ±çŠ¶å›¾é…ç½® - xField: '{x_field}', yField: '{y_field}'")
        print(f"ğŸ” æ•°æ®åˆ—: {df.columns.tolist()}")
        print(f"ğŸ” æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"ğŸ” æ•°æ®å‰5è¡Œ:\n{df.head()}")

        # æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨
        if x_field not in df.columns:
            print(f"âŒ xField '{x_field}' ä¸å­˜åœ¨äºæ•°æ®åˆ—ä¸­")
            print(f"ğŸ” å¯ç”¨å­—æ®µ: {df.columns.tolist()}")
            return {'categories': [], 'series': []}

        if y_field not in df.columns:
            print(f"âŒ yField '{y_field}' ä¸å­˜åœ¨äºæ•°æ®åˆ—ä¸­")
            print(f"ğŸ” å¯ç”¨å­—æ®µ: {df.columns.tolist()}")
            return {'categories': [], 'series': []}

        if not x_field or not y_field:
            print("âŒ ç¼ºå°‘xFieldæˆ–yFieldé…ç½®")
            return {'categories': [], 'series': []}

        try:
            # ç¡®ä¿yå­—æ®µæ˜¯æ•°å€¼ç±»å‹
            print(f"ğŸ”„ è½¬æ¢yå­—æ®µ '{y_field}' ä¸ºæ•°å€¼ç±»å‹")
            df[y_field] = pd.to_numeric(df[y_field], errors='coerce').fillna(0)

            # æ¸…ç†æ•°æ®ï¼Œç§»é™¤NaNå€¼
            df_clean = df.dropna(subset=[x_field, y_field])
            print(f"âœ… æ¸…ç†åæ•°æ®å½¢çŠ¶: {df_clean.shape}")

            if df_clean.empty:
                print("âŒ æ¸…ç†åæ•°æ®ä¸ºç©º")
                return {'categories': [], 'series': []}

            print(f"âœ… {x_field} å”¯ä¸€å€¼: {df_clean[x_field].unique()}")
            print(f"âœ… {y_field} ç»Ÿè®¡: {df_clean[y_field].describe()}")

            # æŒ‰xå­—æ®µåˆ†ç»„å¹¶è®¡ç®—yå­—æ®µçš„èšåˆå€¼
            if 'group_by' in config and config['group_by']:
                group_field = config['group_by']
                if group_field in df_clean.columns:
                    print(f"ğŸ”„ ä½¿ç”¨åˆ†ç»„å­—æ®µ: {group_field}")
                    grouped_data = df_clean.groupby([x_field, group_field])[y_field].sum().unstack(fill_value=0)

                    categories = grouped_data.index.tolist()
                    series = []
                    for column in grouped_data.columns:
                        series.append({
                            'name': str(column),
                            'data': grouped_data[column].tolist()
                        })
                    print(f"âœ… åˆ†ç»„å - åˆ†ç±»æ•°: {len(categories)}, ç³»åˆ—æ•°: {len(series)}")
                else:
                    # åˆ†ç»„å­—æ®µä¸å­˜åœ¨ï¼Œä½¿ç”¨ç®€å•åˆ†ç»„
                    print("âš ï¸ åˆ†ç»„å­—æ®µä¸å­˜åœ¨ï¼Œä½¿ç”¨ç®€å•åˆ†ç»„")
                    grouped_data = df_clean.groupby(x_field)[y_field].sum()
                    categories = grouped_data.index.tolist()
                    series = [{
                        'name': y_field,
                        'data': grouped_data.tolist()
                    }]
            else:
                # ç®€å•åˆ†ç»„ï¼ˆæ— åˆ†ç»„å­—æ®µï¼‰
                print("ğŸ”„ ä½¿ç”¨ç®€å•åˆ†ç»„ï¼ˆæ— åˆ†ç»„å­—æ®µï¼‰")
                grouped_data = df_clean.groupby(x_field)[y_field].sum()
                categories = grouped_data.index.tolist()
                series = [{
                    'name': y_field,
                    'data': grouped_data.tolist()
                }]

            print(f"ğŸ¯ æœ€ç»ˆæ•°æ® - åˆ†ç±»: {categories}")
            print(f"ğŸ¯ æœ€ç»ˆæ•°æ® - ç³»åˆ—: {series}")

            return {
                'categories': categories,
                'series': series
            }
        except Exception as e:
            print(f"âŒ æŸ±çŠ¶å›¾æ•°æ®å¤„ç†é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return {'categories': [], 'series': []}

    def _prepare_line_chart_data(self, df, config):
        """å‡†å¤‡æŠ˜çº¿å›¾æ•°æ® - æ”¯æŒåˆ†ç»„æ•°æ®"""
        x_field = config.get('xField', '')
        y_fields = config.get('yFields', [])
        group_by = config.get('group_by', '')

        # ä½¿ç”¨æ–°çš„é…ç½®å­—æ®µå
        smooth = config.get('smooth', False)
        area_style = config.get('areaStyle', False)
        show_label = config.get('lineShowLabel', False)  # ä½¿ç”¨ç‰¹å®šå­—æ®µå

        if not y_fields:
            single_y_field = config.get('yField', '')
            if single_y_field:
                y_fields = [single_y_field]

        print(f"ğŸ” æŠ˜çº¿å›¾é…ç½® - xField: '{x_field}', yFields: {y_fields}', group_by: '{group_by}'")

        if not x_field or not y_fields:
            return {'categories': [], 'series': []}

        try:
            # æ•°æ®é¢„å¤„ç†
            df_processed = df.copy()
            for y_field in y_fields:
                if y_field in df_processed.columns:
                    df_processed[y_field] = pd.to_numeric(df_processed[y_field], errors='coerce')

            # å¦‚æœæœ‰åˆ†ç»„å­—æ®µ
            if group_by and group_by in df_processed.columns:
                return self._prepare_grouped_line_data(df_processed, x_field, y_fields, group_by, config)
            else:
                return self._prepare_simple_line_data(df_processed, x_field, y_fields, config)

        except Exception as e:
            print(f"âŒ æŠ˜çº¿å›¾æ•°æ®å¤„ç†é”™è¯¯: {str(e)}")
            return {'categories': [], 'series': []}

    def _prepare_map_chart_data(self, df, config):
        """å‡†å¤‡åœ°å›¾æ•°æ® - æ”¯æŒä¸­å›½å„çœå¸‚æ•°æ®"""
        region_field = config.get('regionField', '')
        value_field = config.get('valueField', '')

        print(f"ğŸ—ºï¸ åœ°å›¾é…ç½® - regionField: '{region_field}', valueField: '{value_field}'")
        print(f"ğŸ—ºï¸ æ•°æ®åˆ—: {df.columns.tolist()}")
        print(f"ğŸ—ºï¸ æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"ğŸ—ºï¸ æ•°æ®å‰5è¡Œ:\n{df.head()}")

        if not region_field or not value_field:
            print("âŒ åœ°å›¾ç¼ºå°‘åœ°åŒºå­—æ®µæˆ–æ•°å€¼å­—æ®µé…ç½®")
            return {'data': []}

        try:
            # æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨
            if region_field not in df.columns:
                print(f"âŒ åœ°åŒºå­—æ®µ '{region_field}' ä¸å­˜åœ¨äºæ•°æ®åˆ—ä¸­")
                return {'data': []}
            if value_field not in df.columns:
                print(f"âŒ æ•°å€¼å­—æ®µ '{value_field}' ä¸å­˜åœ¨äºæ•°æ®åˆ—ä¸­")
                return {'data': []}

            # ç¡®ä¿å€¼å­—æ®µæ˜¯æ•°å€¼ç±»å‹
            df[value_field] = pd.to_numeric(df[value_field], errors='coerce')

            # æ¸…ç†æ•°æ®
            df_clean = df.dropna(subset=[region_field, value_field])

            print(f"âœ… æ¸…ç†åæ•°æ®å½¢çŠ¶: {df_clean.shape}")

            if df_clean.empty:
                print("âŒ åœ°å›¾æ•°æ®æ¸…ç†åä¸ºç©ºï¼Œä½¿ç”¨æµ‹è¯•æ•°æ®")
                # è¿”å›æµ‹è¯•æ•°æ®
                test_data = [
                    {'name': 'åŒ—äº¬å¸‚', 'value': 100},
                    {'name': 'ä¸Šæµ·å¸‚', 'value': 80},
                    {'name': 'å¹¿ä¸œçœ', 'value': 120},
                    {'name': 'æ±Ÿè‹çœ', 'value': 90},
                    {'name': 'æµ™æ±Ÿçœ', 'value': 70},
                    {'name': 'å››å·çœ', 'value': 60},
                    {'name': 'æ¹–åŒ—çœ', 'value': 50},
                    {'name': 'æ¹–å—çœ', 'value': 40}
                ]
                return {'data': test_data}

            print(f"âœ… {region_field} å”¯ä¸€å€¼: {df_clean[region_field].unique()}")
            print(f"âœ… {value_field} ç»Ÿè®¡: {df_clean[value_field].describe()}")

            # æŒ‰åœ°åŒºå­—æ®µåˆ†ç»„å¹¶æ±‚å’Œ
            grouped_data = df_clean.groupby(region_field)[value_field].sum().reset_index()

            # è½¬æ¢ä¸ºåœ°å›¾æ•°æ®æ ¼å¼
            map_data = []
            for _, row in grouped_data.iterrows():
                region_name = str(row[region_field])
                value = float(row[value_field])

                # æ ‡å‡†åŒ–åœ°åŒºåç§°
                standardized_region = self._standardize_region_name(region_name)

                map_data.append({
                    'name': standardized_region,
                    'value': value
                })

            print(f"âœ… åœ°å›¾æ•°æ®ç”ŸæˆæˆåŠŸï¼Œå…± {len(map_data)} ä¸ªåœ°åŒº")
            print(f"âœ… åœ°å›¾æ•°æ®ç¤ºä¾‹: {map_data[:3]}")

            return {'data': map_data}

        except Exception as e:
            print(f"âŒ åœ°å›¾æ•°æ®å¤„ç†é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            # è¿”å›æµ‹è¯•æ•°æ®ä½œä¸ºå¤‡é€‰
            test_data = [
                {'name': 'åŒ—äº¬å¸‚', 'value': 100},
                {'name': 'ä¸Šæµ·å¸‚', 'value': 80},
                {'name': 'å¹¿ä¸œçœ', 'value': 120}
            ]
            return {'data': test_data}

    def _standardize_region_name(self, region_name):
        """æ ‡å‡†åŒ–åœ°åŒºåç§°ä»¥åŒ¹é…åœ°å›¾æ•°æ®"""
        # åœ°åŒºåç§°æ˜ å°„ï¼ˆå¯æ ¹æ®éœ€è¦æ‰©å±•ï¼‰
        region_mapping = {
            'åŒ—äº¬': 'åŒ—äº¬å¸‚',
            'å¤©æ´¥': 'å¤©æ´¥å¸‚',
            'ä¸Šæµ·': 'ä¸Šæµ·å¸‚',
            'é‡åº†': 'é‡åº†å¸‚',
            'å†…è’™å¤': 'å†…è’™å¤è‡ªæ²»åŒº',
            'å¹¿è¥¿': 'å¹¿è¥¿å£®æ—è‡ªæ²»åŒº',
            'è¥¿è—': 'è¥¿è—è‡ªæ²»åŒº',
            'å®å¤': 'å®å¤å›æ—è‡ªæ²»åŒº',
            'æ–°ç–†': 'æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº',
            'é¦™æ¸¯': 'é¦™æ¸¯ç‰¹åˆ«è¡Œæ”¿åŒº',
            'æ¾³é—¨': 'æ¾³é—¨ç‰¹åˆ«è¡Œæ”¿åŒº',
            'é»‘é¾™æ±Ÿ': 'é»‘é¾™æ±Ÿçœ',
            'å‰æ—': 'å‰æ—çœ',
            'è¾½å®': 'è¾½å®çœ',
            'æ²³åŒ—': 'æ²³åŒ—çœ',
            'æ²³å—': 'æ²³å—çœ',
            'å±±ä¸œ': 'å±±ä¸œçœ',
            'å±±è¥¿': 'å±±è¥¿çœ',
            'æ±Ÿè‹': 'æ±Ÿè‹çœ',
            'æµ™æ±Ÿ': 'æµ™æ±Ÿçœ',
            'å®‰å¾½': 'å®‰å¾½çœ',
            'ç¦å»º': 'ç¦å»ºçœ',
            'æ±Ÿè¥¿': 'æ±Ÿè¥¿çœ',
            'æ¹–å—': 'æ¹–å—çœ',
            'æ¹–åŒ—': 'æ¹–åŒ—çœ',
            'å¹¿ä¸œ': 'å¹¿ä¸œçœ',
            'æµ·å—': 'æµ·å—çœ',
            'å››å·': 'å››å·çœ',
            'è´µå·': 'è´µå·çœ',
            'äº‘å—': 'äº‘å—çœ',
            'é™•è¥¿': 'é™•è¥¿çœ',
            'ç”˜è‚ƒ': 'ç”˜è‚ƒçœ',
            'é’æµ·': 'é’æµ·çœ'
        }

        # ç§»é™¤å¯èƒ½çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
        cleaned_name = region_name.strip().replace('çœ', '').replace('å¸‚', '').replace('è‡ªæ²»åŒº', '').replace(
            'ç‰¹åˆ«è¡Œæ”¿åŒº', '')

        # è¿”å›æ˜ å°„åçš„åç§°æˆ–åŸåç§°
        return region_mapping.get(cleaned_name, region_name)

    def _prepare_simple_line_data(self, df, x_field, y_fields, config):
        """å‡†å¤‡ç®€å•æŠ˜çº¿å›¾æ•°æ®ï¼ˆæ— åˆ†ç»„ï¼‰"""
        df_sorted = df.sort_values(by=x_field)
        categories = df_sorted[x_field].dropna().unique().tolist()

        series = []
        line_styles = config.get('lineStyles', [])

        for i, y_field in enumerate(y_fields):
            if y_field not in df_sorted.columns:
                continue

            series_data = []
            for category in categories:
                value = df_sorted[df_sorted[x_field] == category][y_field]
                if not value.empty:
                    val = value.iloc[0]
                    series_data.append(None if pd.isna(val) else float(val))
                else:
                    series_data.append(None)

            style_config = line_styles[i] if i < len(line_styles) else {}

            series_item = {
                'name': y_field,
                'data': series_data,
                'type': 'line',
                'smooth': config.get('smooth', False),
                'lineStyle': {
                    'width': style_config.get('width', 2),
                    'color': style_config.get('color', self._get_default_color(i))
                }
            }

            series.append(series_item)

        return {
            'categories': categories,
            'series': series
        }

    def _prepare_grouped_line_data(self, df, x_field, y_fields, group_by, config):
        """å‡†å¤‡åˆ†ç»„æŠ˜çº¿å›¾æ•°æ®"""
        # æŒ‰åˆ†ç»„å­—æ®µå’ŒXè½´å­—æ®µèšåˆæ•°æ®
        pivot_data = df.pivot_table(
            values=y_fields,
            index=x_field,
            columns=group_by,
            aggfunc='mean'
        )

        categories = pivot_data.index.tolist()
        series = []

        # ä¸ºæ¯ä¸ªYè½´å­—æ®µåˆ›å»ºç³»åˆ—
        for y_idx, y_field in enumerate(y_fields):
            if y_field not in pivot_data.columns.get_level_values(0):
                continue

            # è·å–è¯¥Yè½´å­—æ®µçš„æ‰€æœ‰åˆ†ç»„æ•°æ®
            y_data = pivot_data[y_field]

            for group_idx, group_name in enumerate(y_data.columns):
                series_data = y_data[group_name].fillna(0).tolist()

                series_item = {
                    'name': f"{y_field} - {group_name}",
                    'data': series_data,
                    'type': 'line',
                    'smooth': config.get('smooth', False)
                }

                # åº”ç”¨æ ·å¼
                style_idx = y_idx * len(y_data.columns) + group_idx
                series_item['lineStyle'] = {
                    'width': 2,
                    'color': self._get_default_color(style_idx)
                }

                series.append(series_item)

        return {
            'categories': categories,
            'series': series
        }

    def _get_default_color(self, index):
        """è·å–é»˜è®¤é¢œè‰²"""
        colors = ['#5470c6', '#91cc75', '#fac858', '#ee6666', '#73c0de',
                  '#3ba272', '#fc8452', '#9a60b4', '#ea7ccc']
        return colors[index % len(colors)]

    def _prepare_pie_chart_data(self, df, config):
        """å‡†å¤‡é¥¼å›¾æ•°æ® - ä¿®å¤ç‰ˆ"""
        name_field = config.get('nameField', '')
        value_field = config.get('valueField', '')

        print(f"ğŸ” é¥¼å›¾é…ç½® - nameField: '{name_field}', valueField: '{value_field}'")
        print(f"ğŸ” æ•°æ®åˆ—: {df.columns.tolist()}")
        print(f"ğŸ” æ•°æ®å½¢çŠ¶: {df.shape}")

        if not name_field or not value_field:
            print("âŒ é¥¼å›¾ç¼ºå°‘åç§°å­—æ®µæˆ–æ•°å€¼å­—æ®µé…ç½®")
            return {'data': []}

        try:
            # æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨
            if name_field not in df.columns:
                print(f"âŒ åç§°å­—æ®µ '{name_field}' ä¸å­˜åœ¨äºæ•°æ®åˆ—ä¸­")
                return {'data': []}
            if value_field not in df.columns:
                print(f"âŒ æ•°å€¼å­—æ®µ '{value_field}' ä¸å­˜åœ¨äºæ•°æ®åˆ—ä¸­")
                return {'data': []}

            # ç¡®ä¿å€¼å­—æ®µæ˜¯æ•°å€¼ç±»å‹
            df[value_field] = pd.to_numeric(df[value_field], errors='coerce')

            # æ¸…ç†æ•°æ®ï¼Œç§»é™¤NaNå€¼
            df_clean = df.dropna(subset=[name_field, value_field])

            if df_clean.empty:
                print("âŒ æ¸…ç†åæ•°æ®ä¸ºç©º")
                return {'data': []}

            print(f"âœ… æ¸…ç†åæ•°æ®å½¢çŠ¶: {df_clean.shape}")
            print(f"âœ… {name_field} å”¯ä¸€å€¼: {df_clean[name_field].unique()}")
            print(f"âœ… {value_field} ç»Ÿè®¡: {df_clean[value_field].describe()}")

            # æŒ‰åç§°å­—æ®µåˆ†ç»„å¹¶æ±‚å’Œ
            grouped_data = df_clean.groupby(name_field)[value_field].sum()

            data = []
            for name, value in grouped_data.items():
                data.append({
                    'name': str(name),
                    'value': float(value)
                })

            print(f"âœ… é¥¼å›¾æ•°æ®ç”ŸæˆæˆåŠŸï¼Œå…± {len(data)} ä¸ªæ•°æ®é¡¹")
            print(f"âœ… é¥¼å›¾æ•°æ®ç¤ºä¾‹: {data[:3]}")  # æ‰“å°å‰3ä¸ªæ•°æ®é¡¹

            return {'data': data}

        except Exception as e:
            print(f"âŒ é¥¼å›¾æ•°æ®å¤„ç†é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return {'data': []}

    def _prepare_scatter_chart_data(self, df, config):
        """å‡†å¤‡æ•£ç‚¹å›¾æ•°æ® - ä¿®å¤ç‰ˆ"""
        x_field = config.get('xField', '')
        y_field = config.get('yField', '')

        print(f"ğŸ” æ•£ç‚¹å›¾é…ç½® - xField: '{x_field}', yField: '{y_field}'")
        print(f"ğŸ” æ•°æ®åˆ—: {df.columns.tolist()}")

        if not x_field or not y_field:
            print("âŒ æ•£ç‚¹å›¾ç¼ºå°‘Xè½´æˆ–Yè½´å­—æ®µé…ç½®")
            return {'data': [], 'xField': x_field, 'yField': y_field}

        try:
            # æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨
            if x_field not in df.columns:
                print(f"âŒ Xè½´å­—æ®µ '{x_field}' ä¸å­˜åœ¨äºæ•°æ®åˆ—ä¸­")
                return {'data': [], 'xField': x_field, 'yField': y_field}
            if y_field not in df.columns:
                print(f"âŒ Yè½´å­—æ®µ '{y_field}' ä¸å­˜åœ¨äºæ•°æ®åˆ—ä¸­")
                return {'data': [], 'xField': x_field, 'yField': y_field}

            # ç¡®ä¿å­—æ®µæ˜¯æ•°å€¼ç±»å‹
            df[x_field] = pd.to_numeric(df[x_field], errors='coerce')
            df[y_field] = pd.to_numeric(df[y_field], errors='coerce')

            # æ¸…ç†æ•°æ®
            df_clean = df.dropna(subset=[x_field, y_field])

            if df_clean.empty:
                print("âŒ æ•£ç‚¹å›¾æ¸…ç†åæ•°æ®ä¸ºç©º")
                return {'data': [], 'xField': x_field, 'yField': y_field}

            # ç”Ÿæˆæ•£ç‚¹å›¾æ•°æ®æ ¼å¼: [[x1, y1], [x2, y2], ...]
            data = []
            for _, row in df_clean.iterrows():
                x_val = float(row[x_field])
                y_val = float(row[y_field])

                # å¦‚æœæœ‰åˆ†ç»„å­—æ®µï¼Œå¯ä»¥ä½œä¸ºç¬¬ä¸‰ç»´æ•°æ®
                point = [x_val, y_val]
                if 'group_by' in config and config['group_by']:
                    group_field = config['group_by']
                    if group_field in df_clean.columns:
                        # ä½¿ç”¨åˆ†ç»„ä½œä¸ºç¬¬ä¸‰ç»´æ•°æ®ï¼ˆç”¨äºç‚¹çš„å¤§å°æˆ–é¢œè‰²ï¼‰
                        try:
                            group_value = float(hash(str(row[group_field])) % 10 + 1)
                            point.append(group_value)
                        except:
                            point.append(1)
                else:
                    # å¦‚æœæ²¡æœ‰åˆ†ç»„ï¼Œé»˜è®¤å¤§å°ä¸º1
                    point.append(1)

                data.append(point)

            print(f"âœ… æ•£ç‚¹å›¾æ•°æ®ç”ŸæˆæˆåŠŸ - ç‚¹æ•°: {len(data)}")
            print(f"âœ… æ•°æ®ç¤ºä¾‹: {data[:3]}")  # æ‰“å°å‰3ä¸ªç‚¹

            return {
                'data': data,
                'xField': x_field,
                'yField': y_field
            }
        except Exception as e:
            print(f"âŒ æ•£ç‚¹å›¾æ•°æ®å¤„ç†é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return {'data': [], 'xField': x_field, 'yField': y_field}

    def _prepare_radar_chart_data(self, df, config):
        """å‡†å¤‡é›·è¾¾å›¾æ•°æ® - ä¿®å¤ç»Ÿä¸€æœ€å¤§å€¼é—®é¢˜"""
        category_field = config.get('categoryField', '')
        indicator_fields = config.get('indicatorFields', [])

        print(f"ğŸ” é›·è¾¾å›¾é…ç½® - categoryField: '{category_field}', indicatorFields: {indicator_fields}")

        if not category_field or not indicator_fields:
            print("âŒ é›·è¾¾å›¾ç¼ºå°‘ç±»åˆ«å­—æ®µæˆ–æŒ‡æ ‡å­—æ®µé…ç½®")
            return {'indicators': [], 'series': []}

        try:
            # æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨
            if category_field not in df.columns:
                print(f"âŒ ç±»åˆ«å­—æ®µ '{category_field}' ä¸å­˜åœ¨äºæ•°æ®åˆ—ä¸­")
                return {'indicators': [], 'series': []}

            for field in indicator_fields:
                if field not in df.columns:
                    print(f"âŒ æŒ‡æ ‡å­—æ®µ '{field}' ä¸å­˜åœ¨äºæ•°æ®åˆ—ä¸­")
                    return {'indicators': [], 'series': []}

            # ç¡®ä¿æŒ‡æ ‡å­—æ®µæ˜¯æ•°å€¼ç±»å‹
            for field in indicator_fields:
                df[field] = pd.to_numeric(df[field], errors='coerce')

            # æ¸…ç†æ•°æ®
            df_clean = df.dropna(subset=[category_field] + indicator_fields)

            if df_clean.empty:
                print("âŒ é›·è¾¾å›¾æ¸…ç†åæ•°æ®ä¸ºç©º")
                return {'indicators': [], 'series': []}

            print(f"âœ… æ¸…ç†åæ•°æ®å½¢çŠ¶: {df_clean.shape}")

            # å…³é”®ä¿®å¤ï¼šè®¡ç®—ç»Ÿä¸€çš„æœ€å¤§å€¼
            all_values = []
            for field in indicator_fields:
                for category in df_clean[category_field].unique():
                    category_data = df_clean[df_clean[category_field] == category]
                    if len(category_data) > 0:
                        row = category_data.iloc[0]
                        value = float(row[field])
                        all_values.append(value)

            if all_values:
                actual_max = max(all_values)
                # ç»Ÿä¸€æœ€å¤§å€¼ï¼šå®é™…æœ€å¤§å€¼çš„1.5å€ï¼Œå‘ä¸Šå–æ•´
                unified_max = math.ceil(actual_max * 1.5)
                # ç¡®ä¿æœ€å°å€¼è‡³å°‘ä¸º10
                unified_max = max(unified_max, 10)
            else:
                unified_max = 5

            print(f"ğŸ“Š ç»Ÿä¸€æœ€å¤§å€¼è®¡ç®—: å®é™…æœ€å¤§å€¼={max(all_values) if all_values else 0}, ç»Ÿä¸€æœ€å¤§å€¼={unified_max}")

            # æ‰€æœ‰æŒ‡æ ‡ä½¿ç”¨ç›¸åŒçš„æœ€å¤§å€¼
            indicators = []
            for indicator_field in indicator_fields:
                indicators.append({
                    'name': indicator_field,
                    'max': unified_max
                })

            # ä¸ºæ¯ä¸ªç±»åˆ«åˆ›å»ºç³»åˆ—æ•°æ®
            series_data = []
            categories = df_clean[category_field].unique()

            for category in categories:
                category_data = df_clean[df_clean[category_field] == category]
                if len(category_data) > 0:
                    row = category_data.iloc[0]
                    values = [float(row[field]) for field in indicator_fields]

                    series_data.append({
                        'name': str(category),
                        'value': values
                    })

            print(f"âœ… é›·è¾¾å›¾æ•°æ®ç”ŸæˆæˆåŠŸ")
            print(f"   - ç»Ÿä¸€æœ€å¤§å€¼: {unified_max}")
            print(f"   - æŒ‡æ ‡æ•°é‡: {len(indicators)}")
            print(f"   - ç±»åˆ«æ•°é‡: {len(series_data)}")

            return {
                'indicators': indicators,
                'series': series_data
            }
        except Exception as e:
            print(f"âŒ é›·è¾¾å›¾æ•°æ®å¤„ç†é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return {'indicators': [], 'series': []}


class DashboardViewSet(viewsets.ModelViewSet):
    serializer_class = DashboardSerializer
    permission_classes = [permissions.IsAuthenticated]

    def get_queryset(self):
        return Dashboard.objects.filter(created_by=self.request.user)

    def perform_create(self, serializer):
        serializer.save(created_by=self.request.user)

    @action(detail=True, methods=['get'])
    def data(self, request, pk=None):
        """
        è·å–å¯è§†åŒ–å›¾è¡¨æ•°æ® - ä¿®å¤ç‰ˆ
        """
        try:
            visualization = self.get_object()
            dataset = visualization.dataset

            # è·å–æ•°æ®é›†çš„æ‰€æœ‰è®°å½•
            records = DataRecord.objects.filter(dataset=dataset)
            if not records.exists():
                print("âŒ æ•°æ®é›†ä¸ºç©º")
                return Response({
                    'visualization_id': visualization.id,
                    'chart_type': visualization.chart_type.name,
                    'data': {'categories': [], 'series': []},
                    'config': visualization.configuration,
                    'message': 'æ•°æ®é›†ä¸ºç©º'
                })

            data = [record.data for record in records]

            # è½¬æ¢ä¸ºDataFrameè¿›è¡Œå¤„ç†
            df = pd.DataFrame(data)
            print(f"âœ… åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
            print(f"âœ… æ•°æ®åˆ—: {df.columns.tolist()}")
            print(f"âœ… æ•°æ®å‰5è¡Œ:\n{df.head()}")

            # æ ¹æ®å¯è§†åŒ–é…ç½®å¤„ç†æ•°æ®
            config = visualization.configuration
            chart_data = self._prepare_chart_data(df, config, visualization.chart_type)

            print(f"âœ… ç”Ÿæˆçš„å›¾è¡¨æ•°æ®: {chart_data}")

            # å¦‚æœæ˜¯é¥¼å›¾ï¼Œç‰¹åˆ«æ‰“å°æ•°æ®æ ¼å¼
            if visualization.chart_type.name == 'é¥¼å›¾':
                print(f"ğŸ¯ é¥¼å›¾æ•°æ®è¯¦æƒ…:")
                print(f"   - æ•°æ®ç±»å‹: {type(chart_data)}")
                print(f"   - æ•°æ®é”®: {chart_data.keys() if hasattr(chart_data, 'keys') else 'æ— é”®'}")
                if 'data' in chart_data:
                    print(f"   - dataå­—æ®µç±»å‹: {type(chart_data['data'])}")
                    print(
                        f"   - dataå­—æ®µé•¿åº¦: {len(chart_data['data']) if isinstance(chart_data['data'], list) else 'éåˆ—è¡¨'}")
                    if isinstance(chart_data['data'], list) and chart_data['data']:
                        print(f"   - ç¬¬ä¸€ä¸ªæ•°æ®é¡¹: {chart_data['data'][0]}")
                        print(f"   - ç¬¬ä¸€ä¸ªæ•°æ®é¡¹ç±»å‹: {type(chart_data['data'][0])}")

            return Response({
                'visualization_id': visualization.id,
                'chart_type': visualization.chart_type.name,
                'data': chart_data,
                'config': config,
                'message': 'æ•°æ®åŠ è½½æˆåŠŸ'
            })

        except Exception as e:
            print(f"âŒ è·å–å›¾è¡¨æ•°æ®é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return Response(
                {'error': f'è·å–å›¾è¡¨æ•°æ®å¤±è´¥: {str(e)}'},
                status=status.HTTP_400_BAD_REQUEST
            )

    def _prepare_chart_data(self, df, config, chart_type):
        """å‡†å¤‡å›¾è¡¨æ•°æ®ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…åº”è¯¥è°ƒç”¨Visualizationçš„ç›¸åº”æ–¹æ³•ï¼‰"""
        # è¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…é¡¹ç›®ä¸­åº”è¯¥å¤ç”¨Visualizationä¸­çš„æ•°æ®å¤„ç†é€»è¾‘
        if chart_type.name == 'æŸ±çŠ¶å›¾':
            x_field = config.get('xField', '')
            y_field = config.get('yField', '')

            if x_field and y_field in df.columns:
                grouped = df.groupby(x_field)[y_field].sum()
                return {
                    'categories': grouped.index.tolist(),
                    'series': [{'name': y_field, 'data': grouped.tolist()}]
                }

        return {'data': df.to_dict('records')}
