# Copyright (c) 2025 YycKop
# MIT License
# Integrated-Data-Platform-backend/activities/services.py
from django.utils import timezone
from datetime import timedelta
from .models import Activity, ActivityType
import logging

logger = logging.getLogger(__name__)


class ActivityDataAggregator:
    """
    æ´»åŠ¨æ•°æ®èšåˆæœåŠ¡ - ç›´æ¥ä»å„æ¨¡å—è¯»å–æ•°æ®ç”Ÿæˆæ´»åŠ¨è®°å½•
    """

    @staticmethod
    def aggregate_recent_activities(days=30, limit=100):
        """
        èšåˆå„æ¨¡å—çš„æœ€è¿‘æ´»åŠ¨æ•°æ®
        """
        try:
            all_activities = []

            # 1. èšåˆæ•°æ®æºæ´»åŠ¨
            data_source_activities = ActivityDataAggregator._get_data_source_activities(days)
            all_activities.extend(data_source_activities)

            # 2. èšåˆæ•°æ®é›†æ´»åŠ¨
            dataset_activities = ActivityDataAggregator._get_dataset_activities(days)
            all_activities.extend(dataset_activities)

            # 3. èšåˆå¤„ç†æµç¨‹æ´»åŠ¨
            pipeline_activities = ActivityDataAggregator._get_pipeline_activities(days)
            all_activities.extend(pipeline_activities)

            # 4. èšåˆå¯è§†åŒ–æ´»åŠ¨
            visualization_activities = ActivityDataAggregator._get_visualization_activities(days)
            all_activities.extend(visualization_activities)

            # 5. èšåˆçœ‹æ¿æ´»åŠ¨
            dashboard_activities = ActivityDataAggregator._get_dashboard_activities(days)
            all_activities.extend(dashboard_activities)

            # 6. èšåˆAIæ¨¡å‹æ´»åŠ¨
            ai_model_activities = ActivityDataAggregator._get_ai_model_activities(days)
            all_activities.extend(ai_model_activities)

            # æŒ‰æ—¶é—´æ’åºå¹¶é™åˆ¶æ•°é‡
            all_activities.sort(key=lambda x: x['timestamp'], reverse=True)

            logger.info(f"âœ… æˆåŠŸèšåˆ {len(all_activities)} æ¡æ´»åŠ¨è®°å½•")
            return all_activities[:limit]

        except Exception as e:
            logger.error(f"âŒ èšåˆæ´»åŠ¨æ•°æ®å¤±è´¥: {str(e)}")
            return []

    @staticmethod
    def _get_data_source_activities(days):
        """è·å–æ•°æ®æºç›¸å…³æ´»åŠ¨ - ä¿æŒåŸæœ‰æ ¼å¼"""
        try:
            from datasets.models import DataSource  # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            since_date = timezone.now() - timedelta(days=days)
            data_sources = DataSource.objects.filter(
                created_at__gte=since_date
            ).select_related('created_by')

            activities = []
            for data_source in data_sources:
                # ä¿æŒåŸæœ‰æ ¼å¼ï¼šç”¨æˆ· æ“ä½œ ç»“æœåç§°
                description = f'{data_source.created_by.username} åˆ›å»ºäº†æ•°æ®æº "{data_source.name}"'

                activities.append({
                    'id': f"ds_{data_source.id}",
                    'user': data_source.created_by,
                    'user_name': data_source.created_by.username,
                    'activity_type': ActivityType.DATA_SOURCE_CREATED,
                    'activity_type_display': 'åˆ›å»ºæ•°æ®æº',
                    'description': description,
                    'resource_type': 'data_source',
                    'resource_id': data_source.id,
                    'resource_name': data_source.name,
                    'timestamp': data_source.created_at,
                    'metadata': {
                        'data_source_type': data_source.type,
                        'source': 'direct_read'
                    }
                })

            logger.info(f"ğŸ“Š è¯»å–åˆ° {len(activities)} ä¸ªæ•°æ®æºæ´»åŠ¨")
            return activities
        except Exception as e:
            logger.error(f"è·å–æ•°æ®æºæ´»åŠ¨å¤±è´¥: {str(e)}")
            return []

    @staticmethod
    def _get_dataset_activities(days):
        """è·å–æ•°æ®é›†ç›¸å…³æ´»åŠ¨ - ä¿æŒåŸæœ‰æ ¼å¼"""
        try:
            from datasets.models import Dataset  # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            since_date = timezone.now() - timedelta(days=days)
            datasets = Dataset.objects.filter(
                created_at__gte=since_date
            ).select_related('created_by', 'data_source')

            activities = []
            for dataset in datasets:
                # ä¿æŒåŸæœ‰æ ¼å¼ï¼šç”¨æˆ· æ“ä½œ ç»“æœåç§°
                description = f'{dataset.created_by.username} åˆ›å»ºäº†æ•°æ®é›† "{dataset.name}"'

                activities.append({
                    'id': f"dt_{dataset.id}",
                    'user': dataset.created_by,
                    'user_name': dataset.created_by.username,
                    'activity_type': ActivityType.DATASET_CREATED,
                    'activity_type_display': 'åˆ›å»ºæ•°æ®é›†',
                    'description': description,
                    'resource_type': 'dataset',
                    'resource_id': dataset.id,
                    'resource_name': dataset.name,
                    'timestamp': dataset.created_at,
                    'metadata': {
                        'data_source': dataset.data_source.name if dataset.data_source else 'æœªçŸ¥',
                        'record_count': dataset.datarecord_set.count(),
                        'data_type': dataset.data_type,
                        'source': 'direct_read'
                    }
                })

            logger.info(f"ğŸ“Š è¯»å–åˆ° {len(activities)} ä¸ªæ•°æ®é›†æ´»åŠ¨")
            return activities
        except Exception as e:
            logger.error(f"è·å–æ•°æ®é›†æ´»åŠ¨å¤±è´¥: {str(e)}")
            return []

    @staticmethod
    def _get_pipeline_activities(days):
        """è·å–å¤„ç†æµç¨‹ç›¸å…³æ´»åŠ¨ - ä¿æŒåŸæœ‰æ ¼å¼"""
        try:
            from processing.models import ProcessingPipeline  # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            since_date = timezone.now() - timedelta(days=days)
            pipelines = ProcessingPipeline.objects.filter(
                created_at__gte=since_date
            ).select_related('created_by')

            activities = []
            for pipeline in pipelines:
                # æ ¹æ®çŠ¶æ€ç¡®å®šæ“ä½œåŠ¨è¯
                action_verb = "åˆ›å»ºäº†"
                activity_type = ActivityType.PIPELINE_EXECUTED
                activity_display = "åˆ›å»ºå¤„ç†æµç¨‹"

                if pipeline.status == 'running':
                    action_verb = "æ‰§è¡Œäº†"
                    activity_type = ActivityType.PIPELINE_EXECUTED
                    activity_display = "æ‰§è¡Œå¤„ç†æµç¨‹"
                elif pipeline.status == 'completed':
                    action_verb = "å®Œæˆäº†"
                    activity_type = ActivityType.PIPELINE_EXECUTED
                    activity_display = "å®Œæˆå¤„ç†æµç¨‹"

                # ä¿æŒåŸæœ‰æ ¼å¼ï¼šç”¨æˆ· æ“ä½œ ç»“æœåç§°
                description = f'{pipeline.created_by.username} {action_verb}å¤„ç†æµç¨‹ "{pipeline.name}"'

                activities.append({
                    'id': f"pp_{pipeline.id}",
                    'user': pipeline.created_by,
                    'user_name': pipeline.created_by.username,
                    'activity_type': activity_type,
                    'activity_type_display': activity_display,
                    'description': description,
                    'resource_type': 'pipeline',
                    'resource_id': pipeline.id,
                    'resource_name': pipeline.name,
                    'timestamp': pipeline.created_at,
                    'metadata': {
                        'status': pipeline.status,
                        'source': 'direct_read'
                    }
                })

            logger.info(f"ğŸ“Š è¯»å–åˆ° {len(activities)} ä¸ªå¤„ç†æµç¨‹æ´»åŠ¨")
            return activities
        except Exception as e:
            logger.error(f"è·å–å¤„ç†æµç¨‹æ´»åŠ¨å¤±è´¥: {str(e)}")
            return []

    @staticmethod
    def _get_visualization_activities(days):
        """è·å–å¯è§†åŒ–ç›¸å…³æ´»åŠ¨ - ä¿æŒåŸæœ‰æ ¼å¼"""
        try:
            from visualization.models import Visualization  # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            since_date = timezone.now() - timedelta(days=days)
            visualizations = Visualization.objects.filter(
                created_at__gte=since_date
            ).select_related('created_by', 'chart_type', 'dataset')

            activities = []
            for viz in visualizations:
                # ä¿æŒåŸæœ‰æ ¼å¼ï¼šç”¨æˆ· æ“ä½œ ç»“æœåç§°
                description = f'{viz.created_by.username} åˆ›å»ºäº†å¯è§†åŒ– "{viz.name}"'

                activities.append({
                    'id': f"viz_{viz.id}",
                    'user': viz.created_by,
                    'user_name': viz.created_by.username,
                    'activity_type': ActivityType.VISUALIZATION_CREATED,
                    'activity_type_display': 'åˆ›å»ºå¯è§†åŒ–',
                    'description': description,
                    'resource_type': 'visualization',
                    'resource_id': viz.id,
                    'resource_name': viz.name,
                    'timestamp': viz.created_at,
                    'metadata': {
                        'chart_type': viz.chart_type.name,
                        'dataset': viz.dataset.name if viz.dataset else 'æœªçŸ¥',
                        'source': 'direct_read'
                    }
                })

            logger.info(f"ğŸ“Š è¯»å–åˆ° {len(activities)} ä¸ªå¯è§†åŒ–æ´»åŠ¨")
            return activities
        except Exception as e:
            logger.error(f"è·å–å¯è§†åŒ–æ´»åŠ¨å¤±è´¥: {str(e)}")
            return []

    @staticmethod
    def _get_dashboard_activities(days):
        """è·å–çœ‹æ¿ç›¸å…³æ´»åŠ¨ - ä¿æŒåŸæœ‰æ ¼å¼"""
        try:
            from visualization.models import Dashboard  # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            since_date = timezone.now() - timedelta(days=days)
            dashboards = Dashboard.objects.filter(
                created_at__gte=since_date
            ).select_related('created_by')

            activities = []
            for dashboard in dashboards:
                # ä¿æŒåŸæœ‰æ ¼å¼ï¼šç”¨æˆ· æ“ä½œ ç»“æœåç§°
                description = f'{dashboard.created_by.username} åˆ›å»ºäº†çœ‹æ¿ "{dashboard.name}"'

                activities.append({
                    'id': f"db_{dashboard.id}",
                    'user': dashboard.created_by,
                    'user_name': dashboard.created_by.username,
                    'activity_type': ActivityType.DASHBOARD_CREATED,
                    'activity_type_display': 'åˆ›å»ºçœ‹æ¿',
                    'description': description,
                    'resource_type': 'dashboard',
                    'resource_id': dashboard.id,
                    'resource_name': dashboard.name,
                    'timestamp': dashboard.created_at,
                    'metadata': {
                        'chart_count': dashboard.dashboarditem_set.count(),
                        'is_public': dashboard.is_public,
                        'source': 'direct_read'
                    }
                })

            logger.info(f"ğŸ“Š è¯»å–åˆ° {len(activities)} ä¸ªçœ‹æ¿æ´»åŠ¨")
            return activities
        except Exception as e:
            logger.error(f"è·å–çœ‹æ¿æ´»åŠ¨å¤±è´¥: {str(e)}")
            return []

    @staticmethod
    def _get_ai_model_activities(days):
        """è·å–AIæ¨¡å‹ç›¸å…³æ´»åŠ¨ - ä¿æŒåŸæœ‰æ ¼å¼"""
        try:
            from ai.models import AIModel  # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            since_date = timezone.now() - timedelta(days=days)
            ai_models = AIModel.objects.filter(
                created_at__gte=since_date
            ).select_related('created_by')

            activities = []
            for model in ai_models:
                # æ ¹æ®çŠ¶æ€ç¡®å®šæ“ä½œåŠ¨è¯
                if model.status == 'trained' and hasattr(model, 'trained_at') and model.trained_at:
                    action_verb = "è®­ç»ƒäº†"
                    activity_type = ActivityType.AI_MODEL_TRAINED
                    activity_display = "è®­ç»ƒAIæ¨¡å‹"
                    timestamp = model.trained_at
                else:
                    action_verb = "åˆ›å»ºäº†"
                    activity_type = ActivityType.AI_MODEL_TRAINED
                    activity_display = "åˆ›å»ºAIæ¨¡å‹"
                    timestamp = model.created_at

                # ä¿æŒåŸæœ‰æ ¼å¼ï¼šç”¨æˆ· æ“ä½œ ç»“æœåç§°
                description = f'{model.created_by.username} {action_verb}AIæ¨¡å‹ "{model.name}"'

                activities.append({
                    'id': f"ai_{model.id}",
                    'user': model.created_by,
                    'user_name': model.created_by.username,
                    'activity_type': activity_type,
                    'activity_type_display': activity_display,
                    'description': description,
                    'resource_type': 'ai_model',
                    'resource_id': model.id,
                    'resource_name': model.name,
                    'timestamp': timestamp,
                    'metadata': {
                        'model_type': getattr(model, 'model_type', 'unknown'),
                        'status': model.status,
                        'accuracy': getattr(model, 'accuracy', None),
                        'source': 'direct_read'
                    }
                })

            logger.info(f"ğŸ“Š è¯»å–åˆ° {len(activities)} ä¸ªAIæ¨¡å‹æ´»åŠ¨")
            return activities
        except Exception as e:
            logger.error(f"è·å–AIæ¨¡å‹æ´»åŠ¨å¤±è´¥: {str(e)}")
            return []

    @staticmethod
    def sync_activities_to_database():
        """
        å°†èšåˆçš„æ´»åŠ¨æ•°æ®åŒæ­¥åˆ°æ•°æ®åº“
        ç”¨äºä¿®å¤ç¼ºå¤±çš„æ´»åŠ¨è®°å½•
        """
        try:
            aggregated_activities = ActivityDataAggregator.aggregate_recent_activities(days=30)
            created_count = 0

            for agg_activity in aggregated_activities:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„æ´»åŠ¨è®°å½•
                existing = Activity.objects.filter(
                    user=agg_activity['user'],
                    activity_type=agg_activity['activity_type'],
                    resource_type=agg_activity['resource_type'],
                    resource_id=agg_activity['resource_id'],
                    created_at__date=agg_activity['timestamp'].date()
                ).exists()

                if not existing:
                    Activity.objects.create(
                        user=agg_activity['user'],
                        activity_type=agg_activity['activity_type'],
                        description=agg_activity['description'],
                        resource_type=agg_activity['resource_type'],
                        resource_id=agg_activity['resource_id'],
                        resource_name=agg_activity['resource_name'],
                        metadata=agg_activity['metadata'],
                        created_at=agg_activity['timestamp']
                    )
                    created_count += 1

            logger.info(f"âœ… æˆåŠŸåŒæ­¥ {created_count} æ¡æ´»åŠ¨è®°å½•åˆ°æ•°æ®åº“")
            return created_count

        except Exception as e:
            logger.error(f"âŒ åŒæ­¥æ´»åŠ¨æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {str(e)}")
            return 0